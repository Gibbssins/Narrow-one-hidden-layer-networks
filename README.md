# Generalization performance of narrow one-hidden layer networks in the teacher-student setting

This project studies the generalization capabilities of narrow neural networks with a single hidden layer in a teacher-student setup.

We explore how architectural constraints and training dynamics affect learning and generalization, particularly in high-dimensional settings.

## Contents

- Experimental simulations using PyTorch
- Mathematica notebook used to solve the saddle point equation of the theoretical analysis
- Visualization of Free Energy, generalization error and overlap for Quadratic Activation function
- Comparisons between Numerics and Theory for activation functions (ReLU, erf, etc.)

## Requirements

- Python 3.x
- NumPy
- Matplotlib
- PyTorch

## How to Run

1. Clone the repository
2. Install dependencies
3. Run `main.py` or your notebook of choice to reproduce experiments

## Link to the Paper
